{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40cf3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Binarizer, MultiLabelBinarizer\n",
    "from sklearn.metrics import fbeta_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# ### model py files\n",
    "# import CNN_Baseline as baseline\n",
    "# import CNN_Dropout as dropout\n",
    "# import CNN_BatchN as batchN\n",
    "# import Mobilenet as mobnet\n",
    "# import VGG16 as vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9450ea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Choose which GPU to use - HEX SERVER ONLY. Go to https://hex.cs.bath.ac.uk/usage for current usage\n",
    "# import os \n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "### Prevent GPU memory overflow\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "# ### For M1 Mac only\n",
    "# # Import mlcompute module to use the optional set_mlc_device API for device selection with ML Compute.\n",
    "# from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "\n",
    "# # Select CPU device.\n",
    "# mlcompute.set_mlc_device(device_name='gpu') # Available options are 'cpu', 'gpu', and 'any'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5195f2",
   "metadata": {},
   "source": [
    "### Parameter / hyperparameter Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f1a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "INPUT_SHAPE = (128, 128, 3) # Image Dimensions\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.0001 # Learning Rate\n",
    "REG_STRENGTH = 0.01 # Regularization Strength\n",
    "WORKERS = 6 # Multithreading no of threads\n",
    "MAXQ = 10 # Max Queue size for multithreading\n",
    "THRES = [0.2] * 17 # Threshold for truth value of label, applied on sigmoid output.\n",
    "\n",
    "### Hyperparameters\n",
    "DROPOUT_RATE = 0.5\n",
    "PATIENCE = 10\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41368412",
   "metadata": {},
   "source": [
    "### Specify where the model h5 files are saved here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e14a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'hyper_model_set/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85523f22",
   "metadata": {},
   "source": [
    "### Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622dbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset/'\n",
    "TRAIN_PATH = DATASET_PATH + 'train_file'\n",
    "TEST_PATH = DATASET_PATH + 'test_file'\n",
    "\n",
    "TRAIN_CSV_PATH = DATASET_PATH + 'train_label.csv'\n",
    "TEST_CSV_PATH = DATASET_PATH + 'test_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6f6bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "df_train['image_name'] = df_train['image_name'].astype(str)\n",
    "df_test['image_name'] = df_test['image_name'].astype(str)\n",
    "\n",
    "# split multi-label tags in str to a list\n",
    "df_train['tags'] = df_train['tags'].apply(lambda x: x.split(' '))\n",
    "df_test['tags'] = df_test['tags'].apply(lambda x: x.split(' '))\n",
    "\n",
    "X_train_files_o = np.array(df_train['image_name'].tolist()) # filenames\n",
    "X_train_files_o.reshape((X_train_files_o.shape[0], 1))\n",
    "y_train_o = np.array(df_train['tags'].tolist(), dtype=object) # train image tags (ground truth)\n",
    "y_test_o = np.array(df_test['tags'].tolist(), dtype=object) # test image tags (ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513033f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_3577.jpg</td>\n",
       "      <td>[haze, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_10327.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_1243.jpg</td>\n",
       "      <td>[clear, primary, water]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_17066.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_15959.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32378</th>\n",
       "      <td>train_7813.jpg</td>\n",
       "      <td>[agriculture, clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32379</th>\n",
       "      <td>train_32511.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32380</th>\n",
       "      <td>train_5192.jpg</td>\n",
       "      <td>[partly_cloudy, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32381</th>\n",
       "      <td>train_12172.jpg</td>\n",
       "      <td>[agriculture, clear, cultivation, habitation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32382</th>\n",
       "      <td>train_33003.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32383 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_name                                               tags\n",
       "0       train_3577.jpg                                    [haze, primary]\n",
       "1      train_10327.jpg                                   [clear, primary]\n",
       "2       train_1243.jpg                            [clear, primary, water]\n",
       "3      train_17066.jpg                                   [clear, primary]\n",
       "4      train_15959.jpg                                   [clear, primary]\n",
       "...                ...                                                ...\n",
       "32378   train_7813.jpg                      [agriculture, clear, primary]\n",
       "32379  train_32511.jpg                                   [clear, primary]\n",
       "32380   train_5192.jpg                           [partly_cloudy, primary]\n",
       "32381  train_12172.jpg  [agriculture, clear, cultivation, habitation, ...\n",
       "32382  train_33003.jpg                                   [clear, primary]\n",
       "\n",
       "[32383 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### show train and test set...\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f9b5268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_32752.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_7767.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4254.jpg</td>\n",
       "      <td>[agriculture, clear, cultivation, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_23119.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_22101.jpg</td>\n",
       "      <td>[agriculture, clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8091</th>\n",
       "      <td>test_14994.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8092</th>\n",
       "      <td>test_12945.jpg</td>\n",
       "      <td>[haze, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8093</th>\n",
       "      <td>test_9238.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>test_36600.jpg</td>\n",
       "      <td>[cloudy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8095</th>\n",
       "      <td>test_3133.jpg</td>\n",
       "      <td>[clear, primary]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8096 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_name                                        tags\n",
       "0     test_32752.jpg                            [clear, primary]\n",
       "1      test_7767.jpg                            [clear, primary]\n",
       "2      test_4254.jpg  [agriculture, clear, cultivation, primary]\n",
       "3     test_23119.jpg                            [clear, primary]\n",
       "4     test_22101.jpg               [agriculture, clear, primary]\n",
       "...              ...                                         ...\n",
       "8091  test_14994.jpg                            [clear, primary]\n",
       "8092  test_12945.jpg                             [haze, primary]\n",
       "8093   test_9238.jpg                            [clear, primary]\n",
       "8094  test_36600.jpg                                    [cloudy]\n",
       "8095   test_3133.jpg                            [clear, primary]\n",
       "\n",
       "[8096 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c65cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agriculture', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down', 'clear', 'cloudy', 'conventional_mine', 'cultivation', 'habitation', 'haze', 'partly_cloudy', 'primary', 'road', 'selective_logging', 'slash_burn', 'water']\n",
      "\n",
      "17 unique tags\n"
     ]
    }
   ],
   "source": [
    "# check labels in tags and how many there are\n",
    "tags = df_train['tags'].values\n",
    "\n",
    "flat_list = [item for sublist in tags for item in sublist]\n",
    "tags_unique, tags_count = np.unique(flat_list, return_counts=True)\n",
    "labels = list(tags_unique)\n",
    "\n",
    "print(labels)\n",
    "print()\n",
    "print(len(labels), \"unique tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c970369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the labels\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "            \n",
    "plt.bar(range(len(tags_count)), list(tags_count), align='center')\n",
    "plt.xticks(range(len(tags_count)), list(labels), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54171a",
   "metadata": {},
   "source": [
    "### Functions for metrics and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ded6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference fbeta score for training\n",
    "def fbeta_score_K(y_true, y_pred):\n",
    "    beta = 2\n",
    "    beta_squared = beta ** 2\n",
    "    tp = K.sum(y_true * y_pred) + K.epsilon()\n",
    "    fp = K.sum(y_pred) - tp\n",
    "    fn = K.sum(y_true) - tp\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    result = (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "    return result\n",
    "\n",
    "\n",
    "# calc_acc function for processing multi-label predictions into binarizer and calculate f2 score\n",
    "def calc_acc(y_test, y_pred, labels=labels, threshold=0.2):\n",
    "    \n",
    "    array_labels = np.array(labels)\n",
    "    test = y_test\n",
    "    pred = y_pred\n",
    "    \n",
    "    # Binarize pred to 0 and 1...\n",
    "    binarizer = Binarizer(threshold=threshold)\n",
    "    pred = binarizer.fit_transform(pred)\n",
    "    # 0 and 1 to False and True for boolean indexing...\n",
    "    pred = pred > 0\n",
    "    \n",
    "    preds = []\n",
    "    for row in pred:\n",
    "        preds.append(array_labels[row])\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(classes=array_labels)\n",
    "    \n",
    "    test = mlb.fit_transform(test)\n",
    "    preds = mlb.transform(preds)\n",
    "    score = fbeta_score(test, preds, beta=2, average='weighted')\n",
    "    \n",
    "    return test, preds, score\n",
    "\n",
    "\n",
    "# plot function for f2 score and loss after training\n",
    "def plot(result):\n",
    "    train_history = pd.DataFrame(result)\n",
    "\n",
    "    plt.plot(train_history['fbeta_score_K'])\n",
    "    plt.plot(train_history['val_fbeta_score_K'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('fbeta_score_K')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_history['loss'])\n",
    "    plt.plot(train_history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69cfc4a",
   "metadata": {},
   "source": [
    "### Function to process images for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b74f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X_train_files_o, y_train_o, base_flg):\n",
    "    X_train_files, X_val_files, y_train, y_val = train_test_split(X_train_files_o, y_train_o, test_size=0.2, random_state=0)\n",
    "\n",
    "    train_df = pd.DataFrame(list(zip(X_train_files, y_train)), columns = ['image_name', 'tags'])\n",
    "    val_df = pd.DataFrame(list(zip(X_val_files, y_val)), columns = ['image_name', 'tags'])\n",
    "\n",
    "    train_df['tags'] = train_df['tags']\n",
    "    val_df['tags'] = val_df['tags']\n",
    "    \n",
    "    if base_flg == 1:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255\n",
    "            )\n",
    "    else:\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "            )\n",
    "        \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        directory=TRAIN_PATH,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classes=labels,\n",
    "        )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "        )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        directory=TRAIN_PATH,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classes=labels,\n",
    "        )\n",
    "\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "        )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        df_test,\n",
    "        directory=TEST_PATH,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        classes=labels,\n",
    "        shuffle=False,\n",
    "        )\n",
    "\n",
    "    return train_generator,val_generator,test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507bf8ba",
   "metadata": {},
   "source": [
    "### Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fefde255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_directory + 'CNN_Baseline_model' + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deef695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN_Baseline.py is shown here for illustration purpose\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "#from keras.regularizers import l2\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(17, activation='sigmoid') \n",
    "    ])\n",
    "\n",
    "    return model\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efcc4ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25906 validated image filenames belonging to 17 classes.\n",
      "Found 6477 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# This cell was used for training and is shown here for illustration purpose\n",
    "train_generator, val_generator, test_generator = data_generator(X_train_files_o, y_train_o,1)\n",
    "'''\n",
    "adam = Adam(learning_rate=LR)\n",
    "\n",
    "cnn_base_model = baseline.create_model()\n",
    "\n",
    "clear_session()\n",
    "\n",
    "cnn_base_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[fbeta_score_K])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, monitor='val_fbeta_score_K', save_best_only=True, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', min_lr=0.000001)\n",
    "]\n",
    "\n",
    "history = cnn_base_model.fit(train_generator, epochs=EPOCHS, validation_data=val_generator, callbacks=callbacks,\n",
    "                   workers=WORKERS, use_multiprocessing=False, max_queue_size=MAXQ)\n",
    "\n",
    "# print('here', history.history.keys())\n",
    "\n",
    "\n",
    "cnn_base_model.load_weights(model_path)\n",
    "\n",
    "y_pred_b = cnn_base_model.predict(test_generator, workers=WORKERS, use_multiprocessing=False, max_queue_size=MAXQ)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "950b79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cnn_base_model.save(model_path, save_format='h5')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05810f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {'fbeta_score_K': fbeta_score_K} # dependent function needed to load the model\n",
    "\n",
    "cnn_base_model = load_model(model_path, custom_objects=dependencies)\n",
    "\n",
    "y_pred_b = cnn_base_model.predict(test_generator, workers=WORKERS, use_multiprocessing=False, \\\n",
    "                                  max_queue_size=MAXQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2993ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F2 score = 0.828\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      agriculture       0.70      0.77      0.73      2460\n",
      "   artisinal_mine       0.50      0.49      0.50        61\n",
      "      bare_ground       0.17      0.14      0.15       168\n",
      "         blooming       0.07      0.05      0.06        73\n",
      "        blow_down       0.25      0.08      0.12        26\n",
      "            clear       0.94      0.96      0.95      5784\n",
      "           cloudy       0.69      0.85      0.76       381\n",
      "conventional_mine       0.40      0.17      0.24        23\n",
      "      cultivation       0.39      0.39      0.39       927\n",
      "       habitation       0.44      0.47      0.45       735\n",
      "             haze       0.59      0.67      0.63       512\n",
      "    partly_cloudy       0.86      0.87      0.86      1419\n",
      "          primary       0.97      0.98      0.98      7534\n",
      "             road       0.63      0.68      0.65      1619\n",
      "selective_logging       0.11      0.07      0.09        70\n",
      "       slash_burn       0.18      0.07      0.10        42\n",
      "            water       0.48      0.51      0.49      1453\n",
      "\n",
      "        micro avg       0.80      0.83      0.82     23287\n",
      "        macro avg       0.49      0.49      0.48     23287\n",
      "     weighted avg       0.81      0.83      0.82     23287\n",
      "      samples avg       0.85      0.87      0.84     23287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jihoon/anaconda3/envs/tf38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test, pred, test_acc_cnn_base = calc_acc(y_test_o, y_pred_b)\n",
    "print('Test F2 score =', round(test_acc_cnn_base, 3))\n",
    "print(classification_report(test, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d45dc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot(history.history,'CNN_Baseline_train_history.csv')\n",
    "print(\"Test Accuracy Score\", calc_acc(y_test_o, y_pred_b))\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2d85e",
   "metadata": {},
   "source": [
    "### Haze-removed Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815105b",
   "metadata": {},
   "source": [
    "For next models in this notebook, a haze removed image dataset was used. Since the labels and image filenames are still the same as the original dataset imported above, the model can use the haze removed dataset by simply specifying `DATASET_PATH` and its dependencies again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e742a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'dataset-haze-removed/'\n",
    "TRAIN_PATH = DATASET_PATH + 'train_file'\n",
    "TEST_PATH = DATASET_PATH + 'test_file'\n",
    "\n",
    "# TRAIN_CSV_PATH = DATASET_PATH + 'train_label.csv'\n",
    "# TEST_CSV_PATH = DATASET_PATH + 'test_label.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8951c",
   "metadata": {},
   "source": [
    "### E. CNN_Baseline + Haze Removal + Data Augmentation + Batch Normalization + Drop out + Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47818991",
   "metadata": {},
   "source": [
    "The hyperparameters of this model were optimised to increase its prediction F2 score as much as possible. The code used for this optimisation and the optimised hyperparameters are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234119b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter optimisation code\n",
    "\n",
    "'''\n",
    "### Hyperparameter grid\n",
    "DROPOUT_RATE = [0.1, 0.25, 0.5]\n",
    "PATIENCE = [5, 10, 20]\n",
    "\n",
    "### Import model\n",
    "results = []\n",
    "\n",
    "def run(BATCH_SIZE, DROPOUT_RATE, PATIENCE, LR):\n",
    "    \n",
    "\n",
    "    for dropout_rate in DROPOUT_RATE:\n",
    "        print('\\tdropout_rate =', dropout_rate)\n",
    "        for patience in PATIENCE:\n",
    "            print('\\t\\tpatience =', patience)\n",
    "            \n",
    "            train_generator, val_generator, test_generator = data_generator(X_train_files_o, y_train_o, \\\n",
    "                                                                            False, BATCH_SIZE)\n",
    "            model_path = 'CNN_last_weights' + '.h5'\n",
    "            adam = Adam(learning_rate=LR)\n",
    "            cnn_batch_model = batchN.create_model(dropout_rate)\n",
    "            clear_session() # tf backend\n",
    "            cnn_batch_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[fbeta_score_K])\n",
    "\n",
    "            callbacks = [\n",
    "                ModelCheckpoint(model_path, monitor='val_fbeta_score_K', save_best_only=True, mode='max'),\n",
    "                ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', min_lr=0.000001),\n",
    "                EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience),\n",
    "            ]\n",
    "\n",
    "            history = cnn_batch_model.fit(train_generator, epochs=EPOCHS, validation_data=val_generator, \\\n",
    "                                          callbacks=callbacks, workers=WORKERS, use_multiprocessing=False, \\\n",
    "                                          max_queue_size=MAXQ)\n",
    "\n",
    "\n",
    "\n",
    "            cnn_batch_model.load_weights(model_path)\n",
    "\n",
    "            y_pred = cnn_batch_model.predict(test_generator, workers=WORKERS, use_multiprocessing=False, \\\n",
    "                                             max_queue_size=MAXQ)\n",
    "            \n",
    "            test_score = calc_acc(y_test_o, y_pred)\n",
    "            \n",
    "            results.append({'dropout_rate':dropout_rate, 'patience':patience, 'history':history.history, \\\n",
    "                            'test_f2_score':test_score})\n",
    "            \n",
    "run(BATCH_SIZE, DROPOUT_RATE, PATIENCE, LR)\n",
    "df_results = pd.DataFrame(results)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cb09449",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimised Hyperparameters\n",
    "# DROPOUT_RATE = 0.1\n",
    "# PATIENCE = 20\n",
    "# EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a01ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_directory + 'CNN_E_model_0.1_20' + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c88549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN_BatchN.py is shown here for illustration purpose\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "#from keras.regularizers import l2\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "def create_model(dropout):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(128, 128, 3)),\n",
    "        BatchNormalization(),\n",
    "\tConv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\tDropout(dropout),\n",
    "\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "\tBatchNormalization(),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\tDropout(dropout),\n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "\tBatchNormalization(),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\tDropout(dropout),\n",
    "\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "\tBatchNormalization(),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "\tDropout(dropout),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(17, activation='sigmoid') \n",
    "    ])\n",
    "\n",
    "    return model\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46b0b9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25906 validated image filenames belonging to 17 classes.\n",
      "Found 6477 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = data_generator(X_train_files_o, y_train_o, 0)\n",
    "\n",
    "'''\n",
    "adam = Adam(learning_rate=LR)\n",
    "\n",
    "cnn_batch_model = batchN.create_model(DROPOUT_RATE)\n",
    "\n",
    "clear_session()\n",
    "\n",
    "cnn_batch_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[fbeta_score_K])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, monitor='val_fbeta_score_K', save_best_only=True, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', min_lr=0.000001),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE),\n",
    "]\n",
    "\n",
    "history = cnn_batch_model.fit(train_generator, epochs=EPOCHS, validation_data=val_generator, callbacks=callbacks,\n",
    "                   workers=WORKERS, use_multiprocessing=False, max_queue_size=MAXQ)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad12a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cnn_batch_model.save(model_path, save_format='h5')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6979ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_batch_model = load_model(model_path, custom_objects=dependencies)\n",
    "\n",
    "y_pred_hr_da_do_es_bn = cnn_batch_model.predict(test_generator, workers=WORKERS, \\\n",
    "                                                use_multiprocessing=False, max_queue_size=MAXQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f54d4b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F2 score = 0.9\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      agriculture       0.71      0.94      0.81      2460\n",
      "   artisinal_mine       0.69      0.77      0.73        61\n",
      "      bare_ground       0.32      0.26      0.29       168\n",
      "         blooming       0.25      0.16      0.20        73\n",
      "        blow_down       0.06      0.12      0.08        26\n",
      "            clear       0.95      0.98      0.96      5784\n",
      "           cloudy       0.66      0.93      0.77       381\n",
      "conventional_mine       0.79      0.48      0.59        23\n",
      "      cultivation       0.43      0.73      0.54       927\n",
      "       habitation       0.67      0.66      0.66       735\n",
      "             haze       0.50      0.80      0.62       512\n",
      "    partly_cloudy       0.83      0.96      0.89      1419\n",
      "          primary       0.97      1.00      0.98      7534\n",
      "             road       0.64      0.92      0.76      1619\n",
      "selective_logging       0.24      0.50      0.32        70\n",
      "       slash_burn       0.11      0.07      0.09        42\n",
      "            water       0.73      0.75      0.74      1453\n",
      "\n",
      "        micro avg       0.81      0.92      0.86     23287\n",
      "        macro avg       0.56      0.65      0.59     23287\n",
      "     weighted avg       0.83      0.92      0.87     23287\n",
      "      samples avg       0.85      0.94      0.88     23287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test, pred, test_acc_BatchN = calc_acc(y_test_o, y_pred_hr_da_do_es_bn)\n",
    "print('Test F2 score =', round(test_acc_BatchN, 3))\n",
    "print(classification_report(test, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ff09576",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot(history.history,'CNN_E_train_history.csv')\n",
    "print(\"Test Accuracy Score\", calc_acc(y_test_o, y_pred_hr_da_do_es_bn))\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083afd9",
   "metadata": {},
   "source": [
    "### F. MobileNet + Haze Removal + Data Augmentation + Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81e11723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_directory + 'CNN_F_model' + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc916bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mobilenet.py is shown here for illustration purpose\n",
    "\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "#from keras.regularizers import l2\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "\n",
    "# Define MobileNet model for Haze removal\n",
    "def create_model():\n",
    "    img = Input(shape = (128, 128, 3))\n",
    "    model_mob = MobileNet(include_top=False, weights='imagenet', input_tensor=img, input_shape=None, pooling='avg')\n",
    "\n",
    "    final_layer = model_mob.layers[-1].output\n",
    "    dense_layer_1 = Dense(128, activation = 'relu')(final_layer)\n",
    "    output_layer = Dense(17, activation = 'sigmoid')(dense_layer_1)\n",
    "\n",
    "    model = Model(model_mob.input, output_layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73fdf526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25906 validated image filenames belonging to 17 classes.\n",
      "Found 6477 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = data_generator(X_train_files_o, y_train_o,0)\n",
    "\n",
    "'''\n",
    "adam = Adam(learning_rate=LR)\n",
    "\n",
    "mobnet_model = mobnet.create_model()\n",
    "\n",
    "clear_session()\n",
    "mobnet_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[fbeta_score_K])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, monitor='val_fbeta_score_K', save_best_only=True, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', min_lr=0.000001),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE)\n",
    "]\n",
    "\n",
    "history = mobnet_model.fit(train_generator, epochs=EPOCHS, validation_data=val_generator, callbacks=callbacks,\n",
    "                   workers=WORKERS, use_multiprocessing=False, max_queue_size=MAXQ)\n",
    "''';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a27b3a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mobnet_model.save(model_path, save_format='h5')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "688d662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobnet_model = load_model(model_path, custom_objects=dependencies)\n",
    "\n",
    "y_pred_mobnet = mobnet_model.predict(test_generator, workers=WORKERS, use_multiprocessing=False, \\\n",
    "                                     max_queue_size=MAXQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c812d20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F2 score = 0.902\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      agriculture       0.76      0.92      0.83      2460\n",
      "   artisinal_mine       0.68      0.72      0.70        61\n",
      "      bare_ground       0.29      0.37      0.32       168\n",
      "         blooming       0.24      0.14      0.18        73\n",
      "        blow_down       0.33      0.08      0.12        26\n",
      "            clear       0.95      0.98      0.96      5784\n",
      "           cloudy       0.67      0.93      0.78       381\n",
      "conventional_mine       0.60      0.39      0.47        23\n",
      "      cultivation       0.48      0.69      0.57       927\n",
      "       habitation       0.48      0.79      0.60       735\n",
      "             haze       0.55      0.74      0.63       512\n",
      "    partly_cloudy       0.83      0.95      0.88      1419\n",
      "          primary       0.97      0.99      0.98      7534\n",
      "             road       0.71      0.88      0.79      1619\n",
      "selective_logging       0.28      0.30      0.29        70\n",
      "       slash_burn       0.31      0.10      0.15        42\n",
      "            water       0.73      0.82      0.77      1453\n",
      "\n",
      "        micro avg       0.82      0.92      0.87     23287\n",
      "        macro avg       0.58      0.63      0.59     23287\n",
      "     weighted avg       0.84      0.92      0.88     23287\n",
      "      samples avg       0.86      0.94      0.89     23287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test, pred, test_acc_mobnet = calc_acc(y_test_o, y_pred_mobnet)\n",
    "print('Test F2 score =', round(test_acc_mobnet, 3))\n",
    "print(classification_report(test, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d1b7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot(history.history,'CNN_F_train_history.csv')\n",
    "print(\"Test Accuracy Score\", calc_acc(y_test_o, y_pred_mobnet))\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc8479",
   "metadata": {},
   "source": [
    "### G. VGG16 + Haze Removal + Data Augmentation + Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53642467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = model_directory + 'CNN_G_model' + '.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4616fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VGG16.py is shown here for illustration purpose\n",
    "\n",
    "'''\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Flatten, InputLayer\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "\n",
    "INPUT_SHAPE = (128, 128, 3)\n",
    " \n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(INPUT_SHAPE))\n",
    "    model.add(VGG16(weights='imagenet', include_top=False))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(17, activation='sigmoid'))\n",
    "    return model\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "709d23c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25906 validated image filenames belonging to 17 classes.\n",
      "Found 6477 validated image filenames belonging to 17 classes.\n",
      "Found 8096 validated image filenames belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator, test_generator = data_generator(X_train_files_o, y_train_o,0)\n",
    "\n",
    "'''\n",
    "model_path = model_directory + 'CNN_G_model' + '.h5'\n",
    "\n",
    "\n",
    "adam = Adam(learning_rate=LR)\n",
    "\n",
    "vgg16_model = vgg16.create_model()\n",
    "\n",
    "clear_session()\n",
    "vgg16_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[fbeta_score_K])\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, monitor='val_fbeta_score_K', save_best_only=True, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', min_lr=0.000001),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE)\n",
    "]\n",
    "\n",
    "history = vgg16_model.fit(train_generator, epochs=EPOCHS, validation_data=val_generator, callbacks=callbacks,\n",
    "                   workers=WORKERS, use_multiprocessing=False, max_queue_size=MAXQ)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e63944ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vgg16_model.save(model_path, save_format='h5')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e547a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {'fbeta_score_K': fbeta_score_K}\n",
    "vgg16_model = load_model(model_path, custom_objects=dependencies)\n",
    "\n",
    "y_pred_vgg16 = vgg16_model.predict(test_generator, workers=WORKERS, use_multiprocessing=False, \\\n",
    "                                   max_queue_size=MAXQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa99fd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F2 score = 0.907\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      agriculture       0.74      0.93      0.82      2460\n",
      "   artisinal_mine       0.59      0.82      0.68        61\n",
      "      bare_ground       0.39      0.24      0.30       168\n",
      "         blooming       0.33      0.21      0.25        73\n",
      "        blow_down       0.46      0.23      0.31        26\n",
      "            clear       0.94      0.98      0.96      5784\n",
      "           cloudy       0.74      0.90      0.81       381\n",
      "conventional_mine       0.73      0.48      0.58        23\n",
      "      cultivation       0.47      0.69      0.56       927\n",
      "       habitation       0.61      0.77      0.68       735\n",
      "             haze       0.59      0.73      0.66       512\n",
      "    partly_cloudy       0.85      0.97      0.91      1419\n",
      "          primary       0.96      1.00      0.98      7534\n",
      "             road       0.66      0.93      0.77      1619\n",
      "selective_logging       0.31      0.51      0.39        70\n",
      "       slash_burn       0.83      0.12      0.21        42\n",
      "            water       0.72      0.81      0.76      1453\n",
      "\n",
      "        micro avg       0.82      0.93      0.87     23287\n",
      "        macro avg       0.64      0.67      0.63     23287\n",
      "     weighted avg       0.84      0.93      0.88     23287\n",
      "      samples avg       0.87      0.94      0.89     23287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test, pred, test_acc_vgg16 = calc_acc(y_test_o, y_pred_vgg16)\n",
    "print('Test F2 score =', round(test_acc_vgg16, 3))\n",
    "print(classification_report(test, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d6df3",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff67f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed6cf146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed to remove randomness\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7056910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to extract the image features for XGBoost\n",
    "# def extract_features(df, data_path):\n",
    "#     im_features = df.copy()\n",
    "\n",
    "#     N = len(im_features.image_name.values)\n",
    "\n",
    "#     r_mean = np.zeros(N)\n",
    "#     g_mean = np.zeros(N)\n",
    "#     b_mean = np.zeros(N)\n",
    "\n",
    "#     r_std = np.zeros(N)\n",
    "#     g_std = np.zeros(N)\n",
    "#     b_std = np.zeros(N)\n",
    "\n",
    "#     r_max = np.zeros(N)\n",
    "#     g_max = np.zeros(N)\n",
    "#     b_max = np.zeros(N)\n",
    "\n",
    "#     r_min = np.zeros(N)\n",
    "#     g_min = np.zeros(N)\n",
    "#     b_min = np.zeros(N)\n",
    "\n",
    "#     r_kurtosis = np.zeros(N)\n",
    "#     g_kurtosis = np.zeros(N)\n",
    "#     b_kurtosis = np.zeros(N)\n",
    "    \n",
    "#     r_skewness = np.zeros(N)\n",
    "#     g_skewness = np.zeros(N)\n",
    "#     b_skewness = np.zeros(N)\n",
    "\n",
    "#     for i, image_name in enumerate(im_features.image_name.values): \n",
    "#         im = Image.open(data_path + image_name)\n",
    "#         im = np.array(im)[:,:,:3]\n",
    "\n",
    "#         r = im[:,:,0].ravel()\n",
    "#         g = im[:,:,1].ravel()\n",
    "#         b = im[:,:,2].ravel()\n",
    "        \n",
    "#         r_mean[i] = np.mean(r)\n",
    "#         g_mean[i] = np.mean(g)\n",
    "#         b_mean[i] = np.mean(b)\n",
    "\n",
    "#         r_std[i] = np.std(r)\n",
    "#         g_std[i] = np.std(g)\n",
    "#         b_std[i] = np.std(b)\n",
    "\n",
    "#         r_max[i] = np.max(r)\n",
    "#         g_max[i] = np.max(g)\n",
    "#         b_max[i] = np.max(b)\n",
    "\n",
    "#         r_min[i] = np.min(r)\n",
    "#         g_min[i] = np.min(g)\n",
    "#         b_min[i] = np.min(b)\n",
    "\n",
    "#         r_kurtosis[i] = scipy.stats.kurtosis(r)\n",
    "#         g_kurtosis[i] = scipy.stats.kurtosis(g)\n",
    "#         b_kurtosis[i] = scipy.stats.kurtosis(b)\n",
    "        \n",
    "#         r_skewness[i] = scipy.stats.skew(r)\n",
    "#         g_skewness[i] = scipy.stats.skew(g)\n",
    "#         b_skewness[i] = scipy.stats.skew(b)\n",
    "\n",
    "\n",
    "#     im_features['r_mean'] = r_mean\n",
    "#     im_features['g_mean'] = g_mean\n",
    "#     im_features['b_mean'] = b_mean\n",
    "\n",
    "#     im_features['rgb_mean_mean'] = (r_mean + g_mean + b_mean)/3.0\n",
    "\n",
    "#     im_features['r_std'] = r_std\n",
    "#     im_features['g_std'] = g_std\n",
    "#     im_features['b_std'] = b_std\n",
    "\n",
    "#     im_features['rgb_mean_std'] = (r_std + g_std + b_std)/3.0\n",
    "\n",
    "#     im_features['r_max'] = r_max\n",
    "#     im_features['g_max'] = g_max\n",
    "#     im_features['b_max'] = b_max\n",
    "\n",
    "#     im_features['rgb_mean_max'] = (r_max + r_max + b_max)/3.0\n",
    "\n",
    "#     im_features['r_min'] = r_min\n",
    "#     im_features['g_min'] = g_min\n",
    "#     im_features['b_min'] = b_min\n",
    "\n",
    "#     im_features['rgb_mean_min'] = (r_min + g_min + b_min)/3.0\n",
    "\n",
    "#     im_features['r_range'] = r_max - r_min\n",
    "#     im_features['g_range'] = g_max - g_min\n",
    "#     im_features['b_range'] = b_max - b_min\n",
    "\n",
    "#     im_features['r_kurtosis'] = r_kurtosis\n",
    "#     im_features['g_kurtosis'] = g_kurtosis\n",
    "#     im_features['b_kurtosis'] = b_kurtosis\n",
    "    \n",
    "#     im_features['r_skewness'] = r_skewness\n",
    "#     im_features['g_skewness'] = g_skewness\n",
    "#     im_features['b_skewness'] = b_skewness\n",
    "    \n",
    "#     return im_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebcb3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract features\n",
    "# print('Extracting train features')\n",
    "# train_features = extract_features(df_train, TRAIN_PATH + '/')\n",
    "# print('Extracting test features')\n",
    "# test_features = extract_features(df_test, TEST_PATH + '/')\n",
    "\n",
    "# # Save the extracted features\n",
    "# import pickle\n",
    "\n",
    "# train_feat = open(model_directory + 'train_features_xgb.pickle', 'wb')\n",
    "# pickle.dump(train_features, train_feat, protocol=4)\n",
    "# train_feat.close()\n",
    "\n",
    "# test_feat = open(model_directory + 'test_features_xgb.pickle', 'wb')\n",
    "# pickle.dump(test_features, test_feat, protocol=4)\n",
    "# test_feat.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4fd1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled features:\n",
    "import pickle\n",
    "\n",
    "pickle_XGtrain = open(model_directory + 'train_features_xgb.pickle', 'rb')\n",
    "train_features = pickle.load(pickle_XGtrain)\n",
    "\n",
    "pickle_yGtrain = open(model_directory + 'test_features_xgb.pickle', 'rb')\n",
    "test_features = pickle.load(pickle_yGtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c50a2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train dataset\n",
    "X_train_xgb = np.array(train_features.drop(['image_name', 'tags'], axis=1))\n",
    "mlb = MultiLabelBinarizer(classes=labels)\n",
    "y_train_xgb = mlb.fit_transform(y_train_o)\n",
    "\n",
    "n_classes = len(labels) # 17 classes in total\n",
    "#Create X_test dataset\n",
    "X_test_xgb = np.array(test_features.drop(['image_name', 'tags'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffdaddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty array for train and test predictions\n",
    "train_pred_xgb = np.zeros((X_train_xgb.shape[0], n_classes)) # (num_of_train_images, n_classes=17)\n",
    "y_pred_xgb = np.zeros((X_test_xgb.shape[0], n_classes)) # (num_of_test_images, n_classes=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6f15f",
   "metadata": {},
   "source": [
    "The hyperparameters of this model were optimised to increase its prediction F2 score as much as possible. The code used for this optimisation and the optimised hyperparameters are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3af23bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter optimisation code\n",
    "\n",
    "'''\n",
    "# Hyperparameter grid\n",
    "MAX_DEPTH = [2, 5, 10]\n",
    "N_ESTIMATORS = [100, 200, 500]\n",
    "\n",
    "\n",
    "def run(MAX_DEPTH, N_ESTIMATORS):\n",
    "    results = []\n",
    "    \n",
    "    for max_depth in MAX_DEPTH:\n",
    "        print('max_depth =', max_depth)\n",
    "        for n_estimators in N_ESTIMATORS:\n",
    "            print('n_estimators =', n_estimators)\n",
    "#             train_pred_xgb = np.zeros((X_train_xgb.shape[0], n_classes)) # (num_of_train_images, n_classes=17)\n",
    "            y_val_pred = np.zeros((X_val_xgb.shape[0], n_classes)) # (num_of_val_images, n_classes=17)\n",
    "            y_test_pred = np.zeros((X_test_xgb.shape[0], n_classes)) # (num_of_test_images, n_classes=17)\n",
    "\n",
    "            for i in tqdm(range(n_classes), miniters=1, leave=False): \n",
    "#                 print(\"i =\", i, labels[i])\n",
    "                model = xgb.XGBClassifier(max_depth=max_depth, learning_rate=0.1, n_estimators=n_estimators, \\\n",
    "                                          objective='binary:logistic', n_jobs=-1, \\\n",
    "                                          gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                                          subsample=1, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "                                          reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \\\n",
    "                                          base_score=0.5, seed=random_seed, \\\n",
    "                                          use_label_encoder=False, eval_metric='error', \\\n",
    "                                         )\n",
    "\n",
    "                model.fit(X_train_xgb, y_train_xgb[:, i])\n",
    "        \n",
    "                y_val_pred[:, i] = model.predict_proba(X_val_xgb)[:,1] # prediction on test set\n",
    "                y_test_pred[:, i] = model.predict_proba(X_test_xgb)[:,1] # prediction on test set\n",
    "\n",
    "            val_score = calc_acc(y_val, y_val_pred, labels)\n",
    "            test_score = calc_acc(y_test, y_test_pred, labels)\n",
    "            print(\"val_f2_score = {} test_f2_score = {}\".format(round(val_score, 3), round(test_score, 3)))\n",
    "\n",
    "            results.append({'max_depth': max_depth, 'n_estimators': n_estimators, \\\n",
    "                            'val_f2_score': val_score, 'test_f2_score': test_score})\n",
    "                \n",
    "    return results\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdacae1d",
   "metadata": {},
   "source": [
    "#### XGBoost Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffc8732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0 agriculture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jihoon/anaconda3/envs/tf38/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1 artisinal_mine\n",
      "i = 2 bare_ground\n",
      "i = 3 blooming\n",
      "i = 4 blow_down\n",
      "i = 5 clear\n",
      "i = 6 cloudy\n",
      "i = 7 conventional_mine\n",
      "i = 8 cultivation\n",
      "i = 9 habitation\n",
      "i = 10 haze\n",
      "i = 11 partly_cloudy\n",
      "i = 12 primary\n",
      "i = 13 road\n",
      "i = 14 selective_logging\n",
      "i = 15 slash_burn\n",
      "i = 16 water\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_classes): \n",
    "    print(\"i =\", i, labels[i])\n",
    "    model = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=200, \\\n",
    "                              objective='binary:logistic', n_jobs=-1, \\\n",
    "                              gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                              subsample=1, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \\\n",
    "                              base_score=0.5, seed=random_seed, \\\n",
    "                              use_label_encoder=False, eval_metric='error', \\\n",
    "                             )\n",
    "    \n",
    "    model.fit(X_train_xgb, y_train_xgb[:, i])\n",
    "    train_pred_xgb[:, i] = model.predict_proba(X_train_xgb)[:,1] # prediction on train set\n",
    "    y_pred_xgb[:, i] = model.predict_proba(X_test_xgb)[:,1] # prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9f0183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F2 score = 0.8719561482349918\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "      agriculture       0.63      0.92      0.75      2460\n",
      "   artisinal_mine       0.65      0.70      0.68        61\n",
      "      bare_ground       0.33      0.21      0.26       168\n",
      "         blooming       0.18      0.04      0.07        73\n",
      "        blow_down       1.00      0.04      0.07        26\n",
      "            clear       0.90      0.99      0.94      5784\n",
      "           cloudy       0.68      0.88      0.77       381\n",
      "conventional_mine       0.67      0.17      0.28        23\n",
      "      cultivation       0.38      0.62      0.47       927\n",
      "       habitation       0.52      0.76      0.62       735\n",
      "             haze       0.55      0.78      0.64       512\n",
      "    partly_cloudy       0.71      0.90      0.80      1419\n",
      "          primary       0.96      1.00      0.98      7534\n",
      "             road       0.53      0.87      0.66      1619\n",
      "selective_logging       0.19      0.07      0.10        70\n",
      "       slash_burn       0.20      0.02      0.04        42\n",
      "            water       0.41      0.73      0.53      1453\n",
      "\n",
      "        micro avg       0.73      0.91      0.81     23287\n",
      "        macro avg       0.56      0.57      0.51     23287\n",
      "     weighted avg       0.77      0.91      0.83     23287\n",
      "      samples avg       0.80      0.93      0.84     23287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test, pred, test_score = calc_acc(y_test_o, y_pred_xgb)\n",
    "print(\"Test F2 score =\", test_score)\n",
    "print(classification_report(test, pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d670cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
